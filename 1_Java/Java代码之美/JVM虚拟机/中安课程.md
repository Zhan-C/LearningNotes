# 中安课程

## jvm模块

### VisualVM工具的使用

VisualVM，能够监控线程，内存情况，查看方法的CPU时间和内存中的对 象，已被GC的对象，反向查看分配的堆栈(如100个String对象分别由哪几个对象分配出来的)。

VisualVM使用简单，几乎0配置，功能还是比较丰富的，几乎囊括了其它JDK自带命令的所有功能。

- 内存信息
- 线程信息
- Dump堆（本地进程）
- Dump线程（本地进程）
- 打开堆Dump。堆Dump可以用jmap来生成。
- 打开线程Dump
- 生成应用快照（包含内存信息、线程信息等等）
- 性能分析。CPU分析（各个方法调用时间，检查哪些方法耗时多），内存分析（各类对象占用的内存，检查哪些类占用内存多）



#### 什么是JMX？

JMX（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。

监控远程tomcat：
~~~java
#在tomcat的bin目录下，修改catalina.sh，添加如下的参数

JAVA_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"

#这几个参数的意思是：
#-Dcom.sun.management.jmxremote ：允许使用JMX远程管理
#-Dcom.sun.management.jmxremote.port=9999 ：JMX远程连接端口
#-Dcom.sun.management.jmxremote.authenticate=false ：不进行身份认证，任何用户都可以连接
#-Dcom.sun.management.jmxremote.ssl=false ：不使用ssl
保存退出
























































~~~

### G1模块：

####  1：原理：

G1垃圾收集器相对比其他收集器而言，最大的区别在于它取消了年轻代、老年代的物理划分，取而代之的是将堆划分为若干个区域（Region），这些区域中包含了有逻辑上的年轻代、老年代区域。

####  2：这么做的好处：

这样做的好处就是，我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。

####  3:怎么取消cms碎片化问题？

在G1划分的区域中，年轻代的垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或者Survivor空间，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。

这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有cms内存碎片问题的存在了。

####   4: 在G1中，有一种特殊的区域，叫Humongous区域。 

- 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。
- 这些巨型对象，默认直接会被分配在老年代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。
- 为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。

  #### 5:Remembered Set:


于是，G1引进了RSet的概念。它的全称是Remembered Set，其作用是跟踪指向某个堆内的对象引用。并且记录回收哪个区域效果更好，进行top操作

#### 6：配置使用G1：

-XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:+PrintGCDetails -Xmx256m

#### 7：GC Easy  可视化工具：

 GC Easy是一款在线的可视化工具，易用、功能强大，网站：

http://gceasy.io/

![1545182733523](C:\Users\lza\AppData\Local\Temp\1545182733523.png)





# spring cloud与spring boot模块：



## 父类项目工程maven坐标：

```
  <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.0.7.RELEASE</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>

    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <java.version>1.8</java.version>
        <spring-cloud.version>Finchley.SR2</spring-cloud.version>
    </properties>
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>

</dependencies>
    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-dependencies</artifactId>
                <version>${spring-cloud.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
```

## 注册中心eureka：

maven坐标：

```
dependencies>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
    </dependency>
</dependencies>
```

配置文件application.yml：

```
eureka:
  client:
    service-url:
      defaultZone : http://localhost:8761/eureka

    register-with-eureka: false
    fetch-registry: false
spring:
  application:
    name: eureka
server:
  port: 8761
```

启动类注解：

```
@EnableEurekaServer
```

## 分布式配置中心config：

maven坐标：

```
<dependencies>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-config-server</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-bus-amqp</artifactId>
    </dependency>
    <dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-stream-binder-rabbit</artifactId>
</dependency>
</dependencies>
```

配置文件application.yml:

```
server:
  port: 8083

spring:
  application:
    name: shop-config
  cloud:
    config:
      server:
        git:
          uri: https://gitee.com/lza/myconfig.git
  rabbitmq:
    host: 192.168.14.128
management: #暴露触发消息总线的地址
  endpoints:
    web:
      exposure:
        include: bus-refresh
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:8761/eureka/
  instance:
    prefer-ip-address: true
```

启动类注解：

```
@SpringBootApplication
@EnableDiscoveryClient
@EnableConfigServer
```

第五步：在gitwebhook中添加钩子：

<http://127.0.0.1:8083/actuator/bus-refresh> 

## 服务网关 zuul2.0：

pom坐标：

```
<dependencies>

    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-netflix-zuul</artifactId>
    </dependency>
    <dependency>
        <groupId>com.lza</groupId>
        <artifactId>shop_common</artifactId>
        <version>1.0-SNAPSHOT</version>
    </dependency>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-starter-config</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-bus</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactId>spring-cloud-stream-binder-rabbit</artifactId>
    </dependency>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-actuator</artifactId>
    </dependency>
</dependencies>
```



配置文件application.yml:

```
server: 

  port: 8081



eureka:

  client:

    service-url:

      defaultZone: http://127.0.0.1:8761/eureka/

  instance:

    prefer-ip-address: true



spring:

  application:

    name: shop-zuul

  rabbitmq:

    host: 192.168.14.128

    port:  5672

    username: guest

    password: guest

    

zuul:

  routes:

    shop-qa:

     path: /qa/**

     serviceId : shop-qa



    shop-base:

      path: /ba/**

      serviceId: shop-base

      sensitiveHeaders:

    shop-user:

      path: /myuser/**

      serviceId: shop-user



    shop-article:

      path: /article/**

      serviceId: shop-article



    shop-friend:

      path: /fa/**

      serviceId: shop-friend



    shop-recruit:

      path: /rt/**

      serviceId: shop-recruit



    shop-search:

      path: /sc/**

      serviceId: shop-search



    shop-split:

      path: /st/**

      serviceId: shop-split

jwt:

  config:

    key: lza12345547=

    ttl: 360000
```

启动类：

```
@SpringBootApplication
@EnableEurekaClient
@EnableZuulProxy
public class ZuulApplication {
    public static void main(String[] args) {
        SpringApplication.run(ZuulApplication.class);
    }

    @Bean
    public JwtUtil jwtUtil(){
        return new JwtUtil();
    }
    /**
     * 实现动态路由
     */

  @ConfigurationProperties("zuul")
   @RefreshScope
   public  ZuulProperties zuulProperties(){
      return  new ZuulProperties();
  }
}
```
1：经过网关信息头丢失，转发比如cookie等：

shop-base:

      path: /ba/**
    
      serviceId: shop-base
    
      sensitiveHeaders:2：
2：实现动态路由：

  @ConfigurationProperties("zuul")
   @RefreshScope
   public  ZuulProperties zuulProperties(){
      return  new ZuulProperties();
  }

3：zuul与jwt进行权限校验：

```
import com.netflix.zuul.ZuulFilter;
import com.netflix.zuul.context.RequestContext;
import com.netflix.zuul.exception.ZuulException;
import io.jsonwebtoken.Claims;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
import util.JwtUtil;

import javax.servlet.http.HttpServletRequest;
@Component
public class jwttokenFilter extends ZuulFilter {
    @Autowired
    private JwtUtil jwtUtil;
    @Override
    public String filterType() {
        return "pre";
    }

    @Override
    public int filterOrder() {
        return 0;
    }

    @Override
    public boolean shouldFilter() {
        return true;
    }

    /**
     * 过滤器内执行的操作 return 任何ojbect的值都表示继续执行
     * setsendzullRespponse(false)表示不再继续执行
     * @return
     * @throws ZuulException
     */
    @Override
    public Object run() throws ZuulException {
        System.out.println("经过后台过滤器了！");
        RequestContext requestContext = RequestContext.getCurrentContext();
        //request域
        HttpServletRequest request = requestContext.getRequest();

        if(request.getMethod().equals("OPTIONS")){
            return null;
        }

        if(request.getRequestURI().indexOf("login")>0){
            return null;
        }

        //得到头信息
        String header = request.getHeader("Authorization");
        if(header!=null && !"".equals(header)){
            if(header.startsWith("Bearer ")){
                String token = header.substring(7);
                try {
                    Claims claims = jwtUtil.parseJWT(token);
                    String roles = (String) claims.get("roles");
                    if(roles.equals("admin")){
                        //把头信息转发下去，并且放行
                        requestContext.addZuulRequestHeader("Authorization", header);
                        return null;
                    }
                }catch (Exception e){
                    e.printStackTrace();
                    requestContext.setSendZuulResponse(false);//终止运行
                }
            }
        }
        requestContext.setSendZuulResponse(false);//终止运行
        requestContext.setResponseStatusCode(403);
        requestContext.setResponseBody("权限不足");
        requestContext.getResponse().setContentType("text/html;charset=utf-8");
        return null;
    }
```
4：zuul限流：

```
import com.google.common.util.concurrent.RateLimiter;
import com.netflix.zuul.ZuulFilter;
import com.netflix.zuul.exception.ZuulException;
import entity.Result;
import entity.StatusCode;
import org.springframework.stereotype.Component;

@Component
public class RateFilter  extends ZuulFilter {

    //使用令牌桶算法完成限流
    private  static  final RateLimiter ratelimiter =RateLimiter.create(100);
    @Override
    public String filterType() {
        return "pre";
    }

    @Override
    public int filterOrder() {
        return -4;
    }

    @Override
    public boolean shouldFilter() {
        return true;
    }

    @Override
    public Object run() throws ZuulException {
        //如果没有拿到令牌，就不能访问，返回
    if (!ratelimiter.tryAcquire()){
        try {
            throw  new RateException();
        } catch (RateException e) {
            e.printStackTrace();
        }
    }

        return null;
    }

    public class RateException extends Exception {
    }
```
## 搭建基础工程：

基于Snowflake 分布式自增长id：

```
public class IdWorker {
    // 时间起始标记点，作为基准，一般取系统的最近时间（一旦确定不能变动）
    private final static long twepoch = 1288834974657L;
    // 机器标识位数
    private final static long workerIdBits = 5L;
    // 数据中心标识位数
    private final static long datacenterIdBits = 5L;
    // 机器ID最大值
    private final static long maxWorkerId = -1L ^ (-1L << workerIdBits);
    // 数据中心ID最大值
    private final static long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);
    // 毫秒内自增位
    private final static long sequenceBits = 12L;
    // 机器ID偏左移12位
    private final static long workerIdShift = sequenceBits;
    // 数据中心ID左移17位
    private final static long datacenterIdShift = sequenceBits + workerIdBits;
    // 时间毫秒左移22位
    private final static long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits;

    private final static long sequenceMask = -1L ^ (-1L << sequenceBits);
    /* 上次生产id时间戳 */
    private static long lastTimestamp = -1L;
    // 0，并发控制
    private long sequence = 0L;

    private final long workerId;
    // 数据标识id部分
    private final long datacenterId;

    public IdWorker(){
        this.datacenterId = getDatacenterId(maxDatacenterId);
        this.workerId = getMaxWorkerId(datacenterId, maxWorkerId);
    }
    /**
     * @param workerId
     *            工作机器ID
     * @param datacenterId
     *            序列号
     */
    public IdWorker(long workerId, long datacenterId) {
        if (workerId > maxWorkerId || workerId < 0) {
            throw new IllegalArgumentException(String.format("worker Id can't be greater than %d or less than 0", maxWorkerId));
        }
        if (datacenterId > maxDatacenterId || datacenterId < 0) {
            throw new IllegalArgumentException(String.format("datacenter Id can't be greater than %d or less than 0", maxDatacenterId));
        }
        this.workerId = workerId;
        this.datacenterId = datacenterId;
    }
    /**
     * 获取下一个ID
     *
     * @return
     */
    public synchronized long nextId() {
        long timestamp = timeGen();
        if (timestamp < lastTimestamp) {
            throw new RuntimeException(String.format("Clock moved backwards.  Refusing to generate id for %d milliseconds", lastTimestamp - timestamp));
        }

        if (lastTimestamp == timestamp) {
            // 当前毫秒内，则+1
            sequence = (sequence + 1) & sequenceMask;
            if (sequence == 0) {
                // 当前毫秒内计数满了，则等待下一秒
                timestamp = tilNextMillis(lastTimestamp);
            }
        } else {
            sequence = 0L;
        }
        lastTimestamp = timestamp;
        // ID偏移组合生成最终的ID，并返回ID
        long nextId = ((timestamp - twepoch) << timestampLeftShift)
                | (datacenterId << datacenterIdShift)
                | (workerId << workerIdShift) | sequence;

        return nextId;
    }

    private long tilNextMillis(final long lastTimestamp) {
        long timestamp = this.timeGen();
        while (timestamp <= lastTimestamp) {
            timestamp = this.timeGen();
        }
        return timestamp;
    }

    private long timeGen() {
        return System.currentTimeMillis();
    }

    /**
     * <p>
     * 获取 maxWorkerId
     * </p>
     */
    protected static long getMaxWorkerId(long datacenterId, long maxWorkerId) {
        StringBuffer mpid = new StringBuffer();
        mpid.append(datacenterId);
        String name = ManagementFactory.getRuntimeMXBean().getName();
        if (!name.isEmpty()) {
         /*
          * GET jvmPid
          */
            mpid.append(name.split("@")[0]);
        }
      /*
       * MAC + PID 的 hashcode 获取16个低位
       */
        return (mpid.toString().hashCode() & 0xffff) % (maxWorkerId + 1);
    }

    /**
     * <p>
     * 数据标识id部分
     * </p>
     */
    protected static long getDatacenterId(long maxDatacenterId) {
        long id = 0L;
        try {
            InetAddress ip = InetAddress.getLocalHost();
            NetworkInterface network = NetworkInterface.getByInetAddress(ip);
            if (network == null) {
                id = 1L;
            } else {
                byte[] mac = network.getHardwareAddress();
                id = ((0x000000FF & (long) mac[mac.length - 1])
                        | (0x0000FF00 & (((long) mac[mac.length - 2]) << 8))) >> 6;
                id = id % (maxDatacenterId + 1);
            }
        } catch (Exception e) {
            System.out.println(" getDatacenterId: " + e.getMessage());
        }
        return id;
    }
```

在使用方，直接用：

```
@Bean
public IdWorker idWorkker(){
   return new IdWorker(1, 1);
}
```
## 使用 spring data redis：

pom添加依赖：

```
<dependency>
 <groupId>org.springframework.boot</groupId>
 <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```
配置文件application.yml:

```
server: 

  port: 9008

spring: 

  application:  

    name: shop-user #指定服务名

  datasource:

    driverClassName: com.mysql.jdbc.Driver

    url: jdbc:mysql://127.0.0.1:3306/shop_user?characterEncoding=UTF8

    username: root

    password: root

  jpa:

    database: MySQL

    show-sql: true

  redis:

    host: 192.168.14.128

    port: 16380

  rabbitmq:

    host: 192.168.14.128

  zipkin:

    base-url: http://192.168.14.128:9411/

  sleuth:

    sampler:

    probability: 1 #样本采集量，默认为0.1，为了测试这里修改为1，正式环境一般使用默认值。

jwt:

 config:

  key: lza12345547=

  ttl: 360000

eureka:

  client:

    service-url:

      defaultZone: http://127.0.0.1:8761/eureka/

  instance:

    prefer-ip-address: true
```

业务代码使用：

```
@Autowired
private RedisTemplate redisTemplate;
```

```
/**
    * 发送验证码
    * @param iphone
    */
    public void sendsms(String iphone) {
//     //第一步生成6位随机数
//    Random random=new Random();
//    int max=999999;
//    int min=100000;
//    int i = random.nextInt(max);
//    if (i<min){
//       i=i+min;
//    }
      String s = RandomStringUtils.randomNumeric(6);
      System.out.println("接收到验证码是"+s);
      //向缓存添加一份
      redisTemplate.opsForValue().set("s"+iphone,s,6, TimeUnit.DAYS);
      String reidscode=(String) redisTemplate.opsForValue().get("s"+iphone);
      //向消息队列发送一份给用户
      Map<String,String> map =new ConcurrentHashMap<>();
      map.put("iphone",iphone);
      map.put("s",s);
       rabbitTemplate.convertAndSend("sms",map);
   }
```
spring data redis 简单使用说明，大部分是opsForvalue里面

stringRedisTemplate.delete("test");//根据key删除缓存

stringRedisTemplate.opsForValue().set("test", "100",60*10,TimeUnit.SECONDS);//向redis里存入数据和设置缓存时间

stringRedisTemplate.opsForSet().isMember("red_123", "1")//根据key查看集合中是否存在指定数据



## 使用spring data mongodb ：

pom文件：

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-mongodb</artifactId>
</dependency>
```

application.yml:

```
server:

  port: 9006

spring:

  application:

    name: shop-spit

  data:

    mongodb:

      host: 192.168.14.128

      database: spitdb

  redis:

    host: 192.168.14.128

    port: 16380

  rabbitmq:

    host: 192.168.154.128

    port:  5672

    username: guest

    password: guest   

eureka:

  client:

    service-url:

      defaultZone: http://127.0.0.1:8761/eureka/

  instance:

    prefer-ip-address: true
```

在dao层继承MongoRepository：

```
public interface SpitDao extends MongoRepository<Spit, String> {

    public Page<Spit> findByParentid(String parentid, Pageable pageable);
}
```
## 使用 spring data elasticsearch:

maven pom：

```
<dependency>
    <groupId>org.springframework.data</groupId>
    <artifactId>spring-data-elasticsearch</artifactId>

</dependency>
```
修改application.yml配置文件：

```
server:

  port: 9007

  max-http-header-size: 10240

spring:

  application:

    name: shop-search

  data:

    elasticsearch:

      cluster-nodes: 127.0.0.1:9300

  rabbitmq:

    host: 192.168.154.128

    port:  5672

    username: guest

    password: guest    

eureka:

  client:

    service-url:

      defaultZone: http://127.0.0.1:8761/eureka/

  instance:

    prefer-ip-address: true
```

在实体类中编写：

```
mport org.springframework.data.annotation.Id;
import org.springframework.data.elasticsearch.annotations.Document;
import org.springframework.data.elasticsearch.annotations.Field;

import java.io.Serializable;
@Document(indexName = "myorder",type = "order")
public class Article implements Serializable {

    @Id
    private String id;
    //是否索引，就是看该域是否能被搜索。
    //是否分词，就表示搜索的时候是整体匹配还是单词匹配
    //是否存储，就是是否在页面上显示
    @Field(index = true, analyzer="ik_max_word", searchAnalyzer="ik_max_word")
    private String title;

    @Field(index = true, analyzer="ik_max_word", searchAnalyzer="ik_max_word")
    private String content;

    private String state;//审核状态

    public String getId() {
        return id;
    }

    public void setId(String id) {
        this.id = id;
    }

    public String getTitle() {
        return title;
    }

    public void setTitle(String title) {
        this.title = title;
    }

    public String getContent() {
        return content;
    }

    public void setContent(String content) {
        this.content = content;
    }

    public String getState() {
        return state;
    }

    public void setState(String state) {
        this.state = state;
    }
}
```
在dao层添加代码：

```
ublic interface ArticleDao extends ElasticsearchRepository<Article, String> {

    public Page<Article> findByTitleOrContentLike(String title, String content, Pageable pageable);
}
```
### 实现mysql中的数据和elasticsearch的索引数据同步：logstash

编写模板：
input {
  jdbc {
	  # mysql jdbc connection string to our backup databse
	  jdbc_connection_string => "jdbc:mysql://127.0.0.1:3306/shop_article?characterEncoding=UTF8"
	  # the user we wish to excute our statement as
	  jdbc_user => "root"
	  jdbc_password => "root"
	  # the path to our downloaded jdbc driver  
	  jdbc_driver_library => "F:\es\logstash-5.6.8\mysqletc\mysql-connector-java-5.1.46.jar"
	  # the name of the driver class for mysql
	  jdbc_driver_class => "com.mysql.jdbc.Driver"
	  jdbc_paging_enabled => "true"
	  jdbc_page_size => "50"
	  #以下对应着要执行的sql的绝对路径。
	  #statement_filepath => ""
	  statement => "SELECT id,title,content,state FROM tb_article"
	  #定时字段 各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新（测试结果，不同的话请留言指出）
      schedule => "* * * * *"
  }
}

output {
  elasticsearch {
	  #ESIP地址与端口
	  hosts => "127.0.0.1:9200" 
	  #ES索引名称（自己定义的）
	  index => "myorder"
	  #自增ID编号
	  document_id => "%{id}"
	  document_type => "order"
  }
  stdout {
      #以JSON格式输出
      codec => json_lines
  }
}





## 使用 spring data ribbitmq：

pom添加依赖：

```
<dependency>
 <groupId>org.springframework.boot</groupId>
 <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```
application.yml:

```
server: 

  port: 9008

spring: 

  application:  

    name: shop-user #指定服务名

  datasource:

    driverClassName: com.mysql.jdbc.Driver

    url: jdbc:mysql://127.0.0.1:3306/shop_user?characterEncoding=UTF8

    username: root

    password: root

  jpa:

    database: MySQL

    show-sql: true

  redis:

    host: 192.168.14.128

    port: 16380

  rabbitmq:

    host: 192.168.14.128
```

在业务代码中：

```
@Autowired
private RabbitTemplate rabbitTemplate;
/**
	 * 发送验证码 
	 *消息生产者
	 * @param iphone
	 */
    public void sendsms(String iphone) {

		String s = RandomStringUtils.randomNumeric(6);
		System.out.println("接收到验证码是"+s);
		//向缓存添加一份
		redisTemplate.opsForValue().set("s"+iphone,s,6, TimeUnit.DAYS);
		String reidscode=(String) redisTemplate.opsForValue().get("s"+iphone);
		//向消息队列发送一份给用户
		Map<String,String> map =new ConcurrentHashMap<>();
		map.put("iphone",iphone);
		map.put("s",s);
       rabbitTemplate.convertAndSend("sms",map);
	}
```
消息消费者：

```
@Component
@RabbitListener(queues="sms")
public class smsLister {
     @RabbitHandler
    public  void exect(Map<String,String> stringMap){
         System.out.println("手机号"+stringMap.get("iphone"));
         System.out.println("验证码"+stringMap.get("s"));
     }
```
### spring boot 如何推断引导类？

```java
private Class<?> deduceMainApplicationClass() {
    try {
        StackTraceElement[] stackTrace = (new RuntimeException()).getStackTrace();
        StackTraceElement[] var2 = stackTrace;
        int var3 = stackTrace.length;

        for(int var4 = 0; var4 < var3; ++var4) {
            StackTraceElement stackTraceElement = var2[var4];
            if ("main".equals(stackTraceElement.getMethodName())) {
                return Class.forName(stackTraceElement.getClassName());
            }
        }
    } catch (ClassNotFoundException var6) {
        ;
    }
```

通过Main线程执行的堆栈来实现的，不会主动传递main方法的类，通过一个线程，获得当前线程的堆栈，找到带有main方法名，返回当前类 

![1545188635261](C:\Users\lza\AppData\Local\Temp\1545188635261.png)

## k8s教程

### 是什么，作用是什么？

Kubernetes(K8S)是Google在2014年发布的一个开源项目，用于自动化容器化应用程序的部署、扩展和管理。 Kubernetes通常结合docker容器工作，并且整合多个运行着docker容器的主机集群 

Kubernetes是一个全新的基于容器技术的分布式架构领先方案 

使用Kubernetes可以在物理或虚拟机的Kubernetes集群上运行容器化应用，Kubernetes能够提供一个以容器为中 心的基础架构，满足在生产环境中运行应用的一些常见需求，如: 多个进程协同工作 存储系统挂载 Distributing secrets 应用健康检测 应用实例的复制 Pod自动伸缩/扩展 Naming and discovering 负载均衡 滚动更新 资源监控 日志访问 调度应用程序 提供认证和授权 

### 为什么使用Kubernetes 

使用Kubernetes最直接的感受就是我们可以轻装上阵的开发复杂的系统了；其次Kubernetes是在全面拥抱微服务 架构（微服务的核心就是将一个巨大的单体应用拆分成很多小的互相连接的微服务，一个微服务后面可能是多个实 例副本在支撑，副本数量可以随着系统负荷的变化而动态调整）；最后Kubernetes系统架构具备超强的横向扩展 能力。 

### 快速入门：

关闭CentOS防火墙 systemctl disable firewalld  systemctl stop firewalld 

安装etcd和kubernetes软件 yum install -y etcd kubernetes 

启动服务 systemctl start etcd，查看启动状态： systemctl status etcd

  systemctl start docker 

systemctl start kube-apiserver 

systemctl start kube-controller-manager 

systemctl start kube-scheduler

 systemctl start kubelet 

systemctl start kube-proxy 

如果docker启动失败，请参考(vi /etc/sysconfig/selinux 把selinux后面的改为disabled，重启 一波 机器，再重启docker就可以了

docker 卸载：

卸载

1.查询安装过的包

yum list installed | grep docker

docker-engine.x86_64                 17.03.0.ce-1.el7.centos         @dockerrepo

 

2.删除安装的软件包

yum -y remove docker-engine.x86_64



测试

新建

mytomcat.rc.yaml ：

apiVersion: v1
kind: ReplicationController
metadata:
  name: mytomcat
spec:
  replicas: 1
  template:
    metadata:
      name: mytomcat
      labels:
        app: mytomcat
    spec:
      containers:
      - name: mytomcat
        image: tomcat:8 -jre8
        ports:

-  -containerPort: 8080

kubectl create -f mytomcat.rc.yaml

![1545221397425](C:\Users\lza\AppData\Local\Temp\1545221397425.png)

然后新建mytomcat.svc.ymal:

apiVersion: v1
kind: Service
metadata:
  name: mytomcat-svc
spec:
 type:NodePort
 ports:

-port: 8080
nodeport:8089
  selector:
app: mytomcat



#### 外部网不能访问

 在搭建好的k8s集群内创建的容器，只能在其所在的节点上curl可访问，但是在其他任何主机上无法访问 容器占用的端口 解决方案： 

1、vim /etc/sysctl.conf 2、net.ipv4.ip_forward=1 

#### 解决 kubectl get pods时No resources found问题 

1、vim /etc/kubernetes/apiserver 

2、找 到”KUBE_ADMISSION_CONTROL="- admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,Servi ceAccount,ResourceQuota"，去掉ServiceAccount，保存退出。 3、systemctl restart kube-apiserver 重启此服务 浏览测试 

#### docker pull失败:

解决方案1：

1、yum install rhsm -y

 2、docker pull registry.access.redhat.com/rhel7/pod-infrastructure:latest 

如果以上两步解决问题了，那么就不需要在执行下面操作 





docker search pod-infrastructure 

docker pull docker.io/tianyebj/pod-infrastructure 

docker tag tianyebj/pod-infrastructure 192.168.14.130:5000/pod-infrastructure 

docker push 192.168.14.130:5000/pod-infrastructure 



vi /etc/kubernetes/kubelet 修改 KUBELET_POD_INFRA_CONTAINER="--pod-infra-containerimage=192.168.14.130:5000/pod- infrastructure:latest" 

## 理解Future 阻塞问题：

Feture的get()方法不得不等待任务执行完成，如果多个任务提交后，返回的多个feture追一调用get（）方法，将会依次blocking住，任务的执行将会从并行变为串行

## completableFuture：

由于future无法实现异步执行结果链式处理，尽管FutureBlockingDataloader解决方法数据依赖以及顺序执行的问题，不过他将并行执行变为阻塞执行。所以，他不是一个理想的实现。而completableFuture可以帮助提升Future的限制

```
String getResult=CompletableFuture.supplyAsync(()->{return "Hello ";}).thenApplyAsync(v -> v + "world").join();//join方法等待完成
```

## spring webflux：

SSE：【sever sent envents】



### 使用spring webflux开发：

#### 第一步：引入pom依赖：

```
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-mongodb-reactive</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework</groupId>
    <artifactId>spring-webflux</artifactId>

</dependency>
```

### 第二步：在启动类上加入注解

@EnableReactiveMongoRepositories

### 第三步：编写dao层：

注意继承的是响应式的mogondb：

```
import org.springframework.data.mongodb.repository.ReactiveMongoRepository;
```

```
public interface SpitDao extends ReactiveMongoRepository<Spit, String> {
    
}
```

### 第四步：编写controller：

```
//传统写方法
 @GetMapping("/")
 public Flux<Spit> findAll(){
 return  spitDao.findAll();
 }
 //使用新的stream流的方式
 @GetMapping(value = "/stream/all",produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public  Flux<Spit>  getAll(){
     return  spitDao.findAll();
}
```

```
//删除数据
@DeleteMapping("/id")
public Mono<ResponseEntity<Void>> deletespit(@PathVariable String id) {
    return  
    //如果操作数据，并返回一个mono，这时候用flatmap，如果不操作数据，只是转换数据，使用map
    spitDao.findById(id).flatMap(Spit -> spitDao.delete(Spit).then(Mono.just(new ResponseEntity<Void>(HttpStatus.OK))))
            .defaultIfEmpty(new ResponseEntity<>(HttpStatus.NOT_FOUND));
}
```
```
//改数据
@PutMapping("/id")
public Mono<ResponseEntity<Spit>> updateSpit(@PathVariable String id, @RequestBody Spit spit){
    return
            spitDao.findById(id).
                    //操作数据
                    flatMap(sp ->{sp.setComment(spit.getComment());
                     sp.setVisits(spit.getVisits()+1);
                     return spitDao.save(sp);
                    })
                    //转换数据
             .map(spit1 -> new ResponseEntity<Spit>(spit1,HttpStatus.OK))
            .defaultIfEmpty(new ResponseEntity<>(HttpStatus.NOT_FOUND));


}
```

```
@PutMapping(value = "/{id}")，无论什么请求的id，请加上{}
```

```
 //根据id查找
 @GetMapping(value = "/{id}")
public  Mono<ResponseEntity<Spit>> findbyid(@PathVariable String id){

    return  spitDao.findById(id).map(spit -> new ResponseEntity<Spit>(spit,HttpStatus.OK))
            .defaultIfEmpty(new ResponseEntity<>(HttpStatus.NOT_FOUND));
 }
```

**Reactive数据库支持**

Spring Boot 2.0 对一下的数据库提供了自动配置（ auto-configuration ）的reactive的支持：

- MongoDB (spring-boot-starter-data-mongodb-reactive)
- Redis (spring-boot-starter-data-redis-reactive)
- Cassandra (spring-boot-starter-data-cassandra-reactive)

 



## java 9 Flow Api---Reative stream

### 概念：

基于发布与订阅模式处理数据的规范，在java 9被称为 flow Api

背压：交互与反馈，就是发布者与订阅者的一个互动

### 关于响应式流接口

 

### 运行机制

发布数据的时候，使用的是publiser.submit方法

### 常用函数式接口：

```java
**
 * 常用函数式接口 Supplier<T>, 是java.util.Supplier包下的
 * 叫做生成类型的接口，指定接口的类型是什么类型，那么接口的get方法就返回什么类型
 */
public class Test1 {
    public  static String getstring(Supplier<String> spliterator){
      return spliterator.get();
    }

    public static void main(String[] args) {
        //lambda 表达式格式：() -> {};
        String s = getstring(() -> {
            //生成一个字符串
            return "栗英";
        });
          String s2 = getstring(() -> "栗英");
        System.out.println(s);
    }
```



## stream开发

###  stream流编程

stream是一个高级迭代器，不是一个数据结构，不是集合，不会存放；stream关注的是，把数据高效的处理

外部迭代与内部迭代

###  stream流编程创建

![#Fstream  a€lJE  StreamifiRE — €IJE  Collection.stream/parallelStream  Arrays.stream  IntStream/LongStream. range/rangeClosed  Random.ints/longs/doubles  Stream. generate/iterate ](file:///C:/Users/lza/AppData/Local/Temp/msohtmlclip1/01/clip_image001.png) }

//集合创建流

List<String> mylist =new ArrayList<>();

mylist.stream();

//集合创建并行流

mylist.parallelStream();

 

 

//数组创建并行流

int [] nums=new int[10];

Arrays.stream(nums);

 

//使用random创建一个无限流

   new Random().ints().limit(10);

 

 

//产生自己的流

   Stream.generate(() ->random.nextInt()).limit(20);

### stream流中间操作

![1545701041491](C:\Users\lza\AppData\Local\Temp\1545701041491.png)

limit主要使用于无限流

intStrem/longStream 并不是stream的子类。所以要进行装箱boxed



### stream流终止操作

![1545701303678](C:\Users\lza\AppData\Local\Temp\1545701303678.png)

 //并行流foreach模式

str.chars().parallel().forEach(i->System.out.print((char)i));

 

System.out.println();

//并行流forEachOrdered模式,保证了顺序

str.chars().parallel().forEachOrdered(i ->System.out.print((char)i));

 

使用reduce拼接字符串

 Optional<String> reduce = Stream.of(str.split("")).reduce((s1,s2) ->s1+","+s2);

 

//求所有的单词的总长度

Integer reduce3 = Stream.of(str.split("")).map(s ->s.length()).reduce(0,(s1,s2) -> s1+s2);

### 并行流



### 收集器

### stream 运行机制

## lambda

函数式编程思想，输入量和输出量的计算方案，只要能获取结果，谁去做的，怎么做的都不重要。重视是结果，而不是过程

面向对象编程：

做一件事情，找到一个能解决这个事情的对象，调用对象的方法，完成这个功能

冗余的Runnable

```java
 //使用lambda表达式实现：
    new Thread(() -> System.out.println("lambda创建一个线程"+Thread.currentThread().getName())).start();

    new Thread(new Runnable() {
        @Override
        public void run() {
            System.out.println("创建一个线程"+Thread.currentThread().getName());
        }
    }).start();
}
```

lambda 表达式：

分为三部分：

一些参数

一个箭头

一段代码

lambda表达式格式为：

(参数类型  参数名称)  ->{代码块}

格式说明：

小括号中的语法与传统方法参数列表一致；无参数则留空；多个参数用逗号分离

-> 新引入的语法格式，代表指向动作，传递的意思，把参数传递方法体

{}大括号中的语法与传统语法基本一直

```java
/**
 * 按照年龄从小到大排序 ，用lambda表达式来操作有参数，有返回值的
 */
public class personTest {
    public static void main(String[] args) {
        person [] p= {
            new person("栗英",18),
            new person("尚厉娜",38),
            new person("连开花",28)
        };
//        Arrays.sort(p, new Comparator<person>() {
//            @Override
//            public int compare(person o1, person o2) {
//                return o1.getAge()-o2.getAge();
//            }
//        });
        //使用lambda表达式优化匿名内部类 参数列表 -> 方法体
        Arrays.sort(p,(person o1, person o2) -> {return o1.getAge()-o2.getAge();});

        for (person person : p) {
            System.out.println(person);
        }
    }
```

```
**
 *使用函数式接口 Supplier求最大值
 */
public class Test2 {
    public  static  int getMax(Supplier<Integer> sup){
        return sup.get();
    }

    public static void main(String[] args) {
   int [] nums={100,2000,-111,3,-9,11111,33333};
   //lambda 表达式 参数列表 -> 方法体
        int max1 = getMax(() -> {
            int max = nums[0];
            for (int i : nums) {
                if (i > max) {
                    max = i;
                }

            }
            return max;
        });
        System.out.println(max1);
    }
}
```



特点：延迟加载

使用前提：必须存在函数式接口

## 基础知识

**1. 线程的优先级**

Java中线程的优先级分为1-10这10个等级，如果小于1或大于10则JDK抛出IllegalArgumentException()的异常，默认优先级是5。在Java中线程的优先级具有继承性，比如A线程启动B线程，则B线程的优先级与A是一样的。注意程序正确性不能依赖线程的优先级高低，因为操作系统可以完全不理会Java线程对于优先级的决定。



**2. ReentrantLock**

ReentrantLock提供了tryLock方法，tryLock调用的时候，如果锁被其他线程持有，那么tryLock会立即返回，返回结果为false；如果锁没有被其他线程持有，那么当前调用线程会持有锁，并且tryLock返回的结果为true。

> boolean tryLock()
>
> boolean tryLock(long timeout, TimeUnit unit)

可以在构造ReentranLock时使用公平锁，公平锁是指多个线程在等待同一个锁时，必须按照申请锁的先后顺序来一次获得锁。synchronized中的锁时非公平的，默认情况下ReentrantLock也是非公平的，但是可以在构造函数中指定使用公平锁。

> ReentrantLock()
>
> ReentrantLock(boolean fair)

对于ReentrantLock来说，还有一个十分实用的特性，它可以同时绑定多个Condition条件，以实现更精细化的同步控制。

ReentrantLock使用方式如下：

> Lock lock = new ReentrantLock();
>
> lock.lock();
>
> try{
>
> }finally{
>
> ​    lock.unlock();
>
> }
>
> 

**3.Java中的线程池ThreadPoolExecutor**

可以通过ThreadPoolExecutor来创建一个线程池：

> ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)

\1. corePoolSize（线程池基本大小）：当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，也会通过创建一个新线程来执行该任务，直到已创建的线程数大于或等于corePoolSize时，才会根据是否存在空闲线程，来决定是否需要创建新的线程。除了利用提交新任务来创建和启动线程（按需构造），也可以通过 prestartCoreThread() 或 prestartAllCoreThreads() 方法来提前启动线程池中的基本线程。

\2. maximumPoolSize（线程池最大大小）：线程池所允许的最大线程个数。当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。另外，对于无界队列，可忽略该参数。

\3. keepAliveTime（线程存活保持时间）：默认情况下，当线程池的线程个数多于corePoolSize时，线程的空闲时间超过keepAliveTime则会终止。但只要keepAliveTime大于0，allowCoreThreadTimeOut(boolean) 方法也可将此超时策略应用于核心线程。另外，也可以使用setKeepAliveTime()动态地更改参数。

\4. unit（存活时间的单位）：时间单位，分为7类，从细到粗顺序：NANOSECONDS（纳秒），MICROSECONDS（微妙），MILLISECONDS（毫秒），SECONDS（秒），MINUTES（分），HOURS（小时），DAYS（天）；

\5. workQueue（任务队列）：用于传输和保存等待执行任务的阻塞队列。可以使用此队列与线程池进行交互：

- 如果运行的线程数少于 corePoolSize，则 Executor 始终首选添加新的线程，而不进行排队。
- 如果运行的线程数等于或多于 corePoolSize，则 Executor 始终首选将请求加入队列，而不添加新的线程。
- 如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。

\6. threadFactory（线程工厂）：用于创建新线程。由同一个threadFactory创建的线程，属于同一个ThreadGroup，创建的线程优先级都为Thread.NORM_PRIORITY，以及是非守护进程状态。threadFactory创建的线程也是采用new Thread()方式，threadFactory创建的线程名都具有统一的风格：pool-m-thread-n（m为线程池的编号，n为线程池内的线程编号）;

\7. handler（线程饱和策略）：当线程池和队列都满了，则表明该线程池已达饱和状态。

- ThreadPoolExecutor.AbortPolicy：处理程序遭到拒绝，则直接抛出运行时异常 RejectedExecutionException。(默认策略)
- ThreadPoolExecutor.CallerRunsPolicy：调用者所在线程来运行该任务，此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。
- ThreadPoolExecutor.DiscardPolicy：无法执行的任务将被删除。
- ThreadPoolExecutor.DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重新尝试执行任务（如果再次失败，则重复此过程）。

可以使用两个方法向线程池提交任务，分别为execute()和submit()方法。execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。submit()方法用于提交需要返回值的任务，线程池会返回一个Future类型的对象，通过这个对象可以判断任务是否执行成功。如Future<Object> future = executor.submit(task);

利用线程池提供的参数进行监控，参数如下：

- getTaskCount()：线程池需要执行的任务数量。
- getCompletedTaskCount()：线程池在运行过程中已完成的任务数量，小于或等于taskCount。
- getLargestPoolSize()：线程池曾经创建过的最大线程数量，通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。
- getPoolSize()：线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不减。
- getActiveCount()：获取活动的线程数。



**Future & FutureTask**

FutureTask表示的计算是通过Callable来实现的，相当于一种可生产结果的Runnable，并且可以处于一下3种状态：等待运行，正在运行和运行完成。运行表示计算的所有可能结束方式，包括正常结束、由于取消而结束和由于异常而结束等。当FutureTask进入完成状态后，它会永远停止在这个状态上。Future.get的行为取决于任务的状态，如果任务已经完成，那么get会立刻返回结果，否则get将阻塞知道任务进入完成状态，然后返回结果或者异常。FutureTask的使用方式如下：

> public class Preloader
>
> {
>
> ​    //method1
>
> ​    private final static FutureTask<Object> future = new FutureTask<Object>(new Callable<Object>(){
>
> ​        @Override
>
> ​        public Object call() throws Exception
>
> ​        {
>
> ​            return "yes";
>
> ​        }
>
> ​    });
>
>  
>
> ​    //method2
>
> ​    static ExecutorService executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());
>
> ​    private static final Future<Object> futureExecutor = executor.submit(new Callable<Object>(){
>
> ​        @Override
>
> ​        public Object call() throws Exception
>
> ​        {
>
> ​            return "no";
>
> ​        }
>
> ​    });        
>
>  
>
> ​    public static void main(String[] args) throws InterruptedException, ExecutionException
>
> ​    {
>
> ​        executor.shutdown();
>
> ​        future.run();
>
> ​        System.out.println(future.get());
>
> ​        System.out.println(futureExecutor.get());
>
> ​    }
>
> }

运行结果：yes no

Callable表示的任务可以抛出受检查或未受检查的异常，并且任何代码都可能抛出一个Error.无论任务代码抛出什么异常，都会被封装到一个ExecutionException中，并在Future.get中被重新抛出。

FutureTask

用于异步获取执行结果或取消执行任务。通过传入Callable给FutureTask，直接调用run方法执行，之后可以通过FutureTask的get异步方法获得执行结果。FutureTask即使多次调用了run方法，它只会执行一次Callable任务，当然也可以通过cancel来取消执行。 《分布式java应用》P158



reeMap、TreeSet以及JDK1.8之后的HashMap底层都用到了红黑树。红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。

> 问完 HashMap 的底层原理之后，面试官可能就会紧接着问你 HashMap 底层数据结构相关的问题！

### 3.3 既然谈到了红黑树，你给我手绘一个出来吧，然后简单讲一下自己对于红黑树的理解

[![红黑树](https://camo.githubusercontent.com/971cdd1ba73f4e44ea930efcd14a31bdda4b1c23/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f31312f31342f313637313161633239633133386362613f773d38353126683d36313426663d6a70656726733d3334343538)

红黑树最好的解释：算法4中，红黑树等价于2-3树，2-3树他必须二分搜索树的特征，二分搜索树有什么特征，叶子节点大于其左子树所有的值，小于右子树所有的值，这样搜索起来就快了，2-3树是一个绝对平衡的树，红黑树所有的红色节点都是向左倾斜的

**红黑树的应用：**

TreeMap、TreeSet以及JDK1.8之后的HashMap底层都用到了红黑树。

**为什么要用红黑树**

简单来说红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。

### 3.4 红黑树这么优秀，为何不直接使用红黑树得了？

说一下自己对于这个问题的看法：我们知道红黑树属于（自）平衡二叉树，但是为了保持“平衡”是需要付出代价的，红黑树在插入新数据后可能需要通过左旋，右旋、变色这些操作来保持平衡，这费事啊。你说说我们引入红黑树就是为了查找数据快，如果链表长度很短的话，根本不需要引入红黑树的，你引入之后还要付出代价维持它的平衡。但是链表过长就不一样了。至于为什么选 8 这个值呢？通过概率统计所得，这个值是综合查询成本和新增元素成本得出的最好的一个值。



### 3.5 HashMap 和 Hashtable 的区别/HashSet 和 HashMap 区别

**HashMap 和 Hashtable 的区别**

1. **线程是否安全：** HashMap 是非线程安全的，HashTable 是线程安全的；HashTable 内部的方法基本都经过 `synchronized`修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）；
2. **效率：** 因为线程安全的问题，HashMap 要比 HashTable 效率高一点。另外，HashTable 基本被淘汰，不要在代码中使用它；
3. **对Null key 和Null value的支持：** HashMap 中，null 可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为 null。。但是在 HashTable 中 put 进的键值只要有一个 null，直接抛出 NullPointerException。
4. **初始容量大小和每次扩充容量大小的不同 ：** ①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为2的幂次方大小（HashMap 中的`tableSizeFor()`方法保证，下面给出了源代码）。也就是说 HashMap 总是使用2的幂作为哈希表的大小,后面会介绍到为什么是2的幂次方。
5. **底层数据结构：** JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。

**HashSet 和 HashMap 区别**

如果你看过 HashSet 源码的话就应该知道：HashSet 底层就是基于 HashMap 实现的。（HashSet 的源码非常非常少，因为除了 clone() 方法、writeObject()方法、readObject()方法是 HashSet 自己不得不实现之外，其他方法都是直接调用 HashMap 中的方法。）

####  为什么两个对象有相同的hashcode值，它们也不一定是相等的？

在这里解释一位小伙伴的问题。以下内容摘自《Head Fisrt Java》。

因为hashCode() 所使用的杂凑算法也许刚好会让多个对象传回相同的杂凑值。越糟糕的杂凑算法越容易碰撞，但这也与数据值域分布的特性有关（所谓碰撞也就是指的是不同的对象得到相同的 hashCode）。

我们刚刚也提到了 HashSet,如果 HashSet 在对比的时候，同样的 hashcode 有多个对象，它会使用 equals() 来判断是否真的相同。也就是说 hashcode 只是用来缩小查找成本

###  ==与equals

**==** : 它的作用是判断两个对象的地址是不是相等。即，判断两个对象是不是同一个对象。(基本数据类型==比较的是值，引用数据类型==比较的是内存地址)

**equals()** : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况：

- 情况1：类没有覆盖equals()方法。则通过equals()比较该类的两个对象时，等价于通过“==”比较这两个对象。
- 情况2：类覆盖了equals()方法。一般，我们都覆盖equals()方法来两个对象的内容相等；若它们的内容相等，则返回true(即，认为这两个对象相等)。

### 谈谈 synchronized 和 ReenTrantLock 的区别

**① 两者都是可重入锁**

两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。

**② synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API**

synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。

**③ ReenTrantLock 比 synchronized 增加了一些高级功能**

相比synchronized，ReenTrantLock增加了一些高级功能。主要来说主要有三点：**①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）**

- **ReenTrantLock提供了一种能够中断等待锁的线程的机制**，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
- **ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。** ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。
- synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），**线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”** ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。

如果你想使用上述功能，那么选择ReenTrantLock是一个不错的选择。

**④ 两者的性能已经相差无几**

在JDK1.6之前，synchronized 的性能是比 ReenTrantLock 差很多。具体表示为：synchronized 关键字吞吐量岁线程数的增加，下降得非常严重。而ReenTrantLock 基本保持一个比较稳定的水平。我觉得这也侧面反映了， synchronized 关键字还有非常大的优化余地。后续的技术发展也证明了这一点，我们上面也讲了在 JDK1.6 之后 JVM 团队对 synchronized 关键字做了很多优化。JDK1.6 之后，synchronized 和 ReenTrantLock 的性能基本是持平了。所以网上那些说因为性能才选择 ReenTrantLock 的文章都是错的！JDK1.6之后，性能已经不是选择synchronized和ReenTrantLock的影响因素了！而且虚拟机在未来的性能改进中会更偏向于原生的synchronized，所以还是提倡在synchronized能满足你的需求的情况下，优先考虑使用synchronized关键字来进行同步！优化后的synchronized和ReenTrantLock一样，在很多地方都是用到了CAS操作。



### Java 提供了哪几种线程池？他们各自的使用场景是什么？

#### Java 主要提供了下面4种线程池

- **FixedThreadPool** ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。
- **SingleThreadExecutor：** 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
- **CachedThreadPool：** 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。
- **ScheduledThreadPoolExecutor：**主要用来在给定的延迟后运行任务，或者定期执行任务。ScheduledThreadPoolExecutor又分为：ScheduledThreadPoolExecutor（包含多个线程）和SingleThreadScheduledExecutor （只包含一个线程）两种。

#### 各种线程池的适用场景介绍

- **FixedThreadPool：** 适用于为了满足资源管理需求，而需要限制当前线程数量的应用场景。它适用于负载比较重的服务器；
- **SingleThreadExecutor：** 适用于需要保证顺序地执行各个任务并且在任意时间点，不会有多个线程是活动的应用场景。
- **CachedThreadPool：** 适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器；
- **ScheduledThreadPoolExecutor：** 适用于需要多个后台执行周期任务，同时为了满足资源管理需求而需要限制后台线程的数量的应用场景，
- **SingleThreadScheduledExecutor：** 适用于需要单个后台线程执行周期任务，同时保证顺序地执行各个任务的应用场景。

### 创建的线程池的方式

**（1） 使用 Executors 创建**  ɪɡˈzɛkjətɚ

我们上面刚刚提到了 Java 提供的几种线程池，通过 Executors 工具类我们可以很轻松的创建我们上面说的几种线程池。但是实际上我们一般都不是直接使用Java提供好的线程池，另外在《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 构造函数 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。

```
Executors 返回线程池对象的弊端如下：

FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致OOM。
CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。
```

**（2） ThreadPoolExecutor的构造函数创建**

我们可以自己直接调用 ThreadPoolExecutor 的构造函数来自己创建线程池。在创建的同时，给 BlockQueue 指定容量就可以了。示例如下：

```
private static ExecutorService executor = new ThreadPoolExecutor(13, 13,
        60L, TimeUnit.SECONDS,
        new ArrayBlockingQueue(13));
```

这种情况下，一旦提交的线程数超过当前可用线程数时，就会抛出java.util.concurrent.RejectedExecutionException，这是因为当前线程池使用的队列是有边界队列，队列已经满了便无法继续处理新的请求。但是异常（Exception）总比发生错误（Error）要好。

**使用开源类库**

Hollis 大佬之前在他的文章中也提到了：“除了自己定义ThreadPoolExecutor外。还有其他方法。这个时候第一时间就应该想到开源类库，如apache和guava等。”他推荐使用guava ɡwɑvə 提供的ThreadFactoryBuilder来创建线程池。下面是参考他的代码示例：

```
public class ExecutorsDemo {

    private static ThreadFactory namedThreadFactory = new ThreadFactoryBuilder()
        .setNameFormat("demo-pool-%d").build();

    private static ExecutorService pool = new ThreadPoolExecutor(5, 200,
        0L, TimeUnit.MILLISECONDS,
        new LinkedBlockingQueue<Runnable>(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());

    public static void main(String[] args) {

        for (int i = 0; i < Integer.MAX_VALUE; i++) {
            pool.execute(new SubThread());
        }
    }
}
```

通过上述方式创建线程时，不仅可以避免OOM的问题，还可以自定义线程名称，更加方便的出错的时候溯源。 

##  为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？

这是另一个非常经典的java多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！

new一个Thread，线程进入了新建状态;调用start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start()会执行线程的相应准备工作，然后自动执行run()方法的内容，这是真正的多线程工作。 而直接执行run()方法，会把run方法当成一个mian线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

**总结： 调用start方法方可启动线程并使线程进入就绪状态，而run方法只是thread的一个普通方法调用，还是在主线程里执行。**



#### String为什么是不可变的吗？

简单来说就是String类利用了final修饰的char类型数组存储字符，源码如下图所以：

```
    /** The value is used for character storage. */
    private final char value[];
```

#### String真的是不可变的吗？

我觉得如果别人问这个问题的话，回答不可变就可以了。 下面只是给大家看两个有代表性的例子：

**1) String不可变但不代表引用不可以变**

```
		String str = "Hello";
		str = str + " World";
		System.out.println("str=" + str);
```

结果：

```
str=Hello World
```

解析：

实际上，原来String的内容是不变的，只是str由原来指向"Hello"的内存地址转为指向"Hello World"的内存地址而已，也就是说多开辟了一块内存区域给"Hello World"字符串。

**2) 通过反射是可以修改所谓的“不可变”对象**

```
		// 创建字符串"Hello World"， 并赋给引用s
		String s = "Hello World";

		System.out.println("s = " + s); // Hello World

		// 获取String类中的value字段
		Field valueFieldOfString = String.class.getDeclaredField("value");

		// 改变value属性的访问权限
		valueFieldOfString.setAccessible(true);

		// 获取s对象上的value属性的值
		char[] value = (char[]) valueFieldOfString.get(s);

		// 改变value所引用的数组中的第5个字符
		value[5] = '_';

		System.out.println("s = " + s); // Hello_World
```

结果：

```
s = Hello World
s = Hello_World
```

解析：

用反射可以访问私有成员， 然后反射出String对象中的value属性， 进而改变通过获得的value引用改变数组的结构。但是一般我们不会这么做，这里只是简单提一下有这个东西。



## HashMap 的长度为什么是2的幂次方

为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀。我们上面也讲到了过了，Hash 值的范围值-2147483648到2147483648，前后加起来大概40亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个40亿长度的数组，内存是放不下的。所以这个散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。这个数组下标的计算方法是“ `(n - 1) & hash` ”。（n代表数组长度）。这也就解释了 HashMap 的长度为什么是2的幂次方。

**这个算法应该如何设计呢？**

我们首先可能会想到采用%取余的操作来实现。但是，重点来了：**“取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是 length 是2的 n 次方；）。”** 并且 **采用二进制位操作 &，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是2的幂次方**



# JDK1.8 的ArrayList 的默认构造函数，初始化的list的长度为0

你好：
/**
*默认构造函数，其默认初始容量为10
*/
public ArrayList() {
this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
}

DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为0
初始化为10，是在首次add() 的时候进行的

标注对应的位置 这部分我记得我写的也是10 但是这个初始其实是空数组 当添加第一个元素的时候才变成10 





### 使用Sentinel ：

引入坐标：

```
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>
</dependency>
```


编写配置文件：

```
management.endpoints.web.exposure.include=*
spring.cloud.sentinel.transport.dashboard=localhost:8080

```
controller里面添加注解：

```
@SentinelResource("resource")
```



## Webmagic  ：爬虫框架

四大组件 ：

Downloader负责从互联网上下载页面，以便后续处理。ebMagic默认使用了 ApacheHttpClient作为下载工具。



 PageProcessor PageProcessor负责解析页面，抽取有用信息，以及发现新的链接。WebMagic使用Jsoup 作为HTML解析工具，并基于其开发了解析XPath的工具Xsoup。 在这四个组件中，PageProcessor对于每个站点每个页面都不一样，是需要使用者定制的部 分。



 Scheduler Scheduler负责管理待抓取的URL，以及一些去重的工作。WebMagic默认提供了JDK的内 存队列来管理URL，并用集合来进行去重。也支持使用Redis进行分布式管理。

 

Pipeline Pipeline负责抽取结果的处理，包括计算、持久化到文件、数据库等。WebMagic默认提供 了“输出到控制台”和“保存到文件”两种结果处理方案。 





```java
@EnableScheduling 执行定时任务地
```




spring boot 2.0改变：

## spring boot 2 变动

- @ConditionalOnBean现在的判断条件由OR变为了AND。
- 默认的连接池已经由Tomcat切换到了HikariCP
- Spring Boot现在默认是使用CGLIB代理，同时包含AOP支持
- Spring Boot 2.0 是建立在Spring Framework 5.0之上的（最低要求）。Spring 5最大的亮点就是reactive
- 一个全新的spring-boot-starter-json starter 聚合了很多常用的json工具，可以支持对json的读写
- 基本支持了Java 9。之所以是“基本”，是因为还没得到用户的验证。
- TLS 配置 和 HTTP/2 支持，你现在也可以为你的MVC 或 WebFlux应用配置HTTP/2：使用server.http2.enabled。
- @KafkaListener支持使用@SendTo